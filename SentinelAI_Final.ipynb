{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c706c8dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import re\n",
    "import json\n",
    "import os \n",
    "import pandas as pd\n",
    "import random\n",
    "from faker import Faker\n",
    "from datetime import datetime, timedelta\n",
    "from pathlib import Path\n",
    "from spacy.matcher import Matcher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b76fe55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SpaCy model 'en_core_web_lg' loaded successfully.\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    nlp = spacy.load(\"en_core_web_lg\") # Large English model for for better accuracy\n",
    "except OSError:\n",
    "    print(\"SpaCy 'en_core_web_lg' model not found. Please ensure it's downloaded by running:\")\n",
    "    print(\"!python -m spacy download en_core_web_lg\")\n",
    "    raise # Re-raise the error to stop execution if model is crucial\n",
    "print(\"SpaCy model 'en_core_web_lg' loaded successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cfb1c7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Contextual Rules ---\n",
    "# Define patterns to provide contextual clues for more accurate PII detection.\n",
    "# This helps disambiguate words like \"Will\" as a name versus a verb.\n",
    "CONTEXTUAL_RULES = {\n",
    "    \"HIGH_CONF_PERSON\": [\n",
    "        [{\"LOWER\": \"mr\"}, {\"POS\": \"PROPN\"}],  # \"Mr. John\"\n",
    "        [{\"LOWER\": \"dr\"}, {\"POS\": \"PROPN\"}],  # \"Dr. Smith\"\n",
    "        [{\"TEXT\": \"my\"}, {\"TEXT\": \"name\"}, {\"TEXT\": \"is\"}, {\"POS\": \"PROPN\", \"OP\": \"+\"}], # \"my name is John Smith\"\n",
    "        [{\"LOWER\": {\"IN\": [\"contact\", \"sent\", \"by\"]}}, {\"POS\": \"PROPN\", \"OP\": \"+\"}] # \"sent by Jane\"\n",
    "    ],\n",
    "    \"LOW_CONF_PERSON\": [\n",
    "        [{\"TEXT\": \"Will\"}, {\"POS\": \"VERB\", \"OP\": \"?\"}], # \"We will finalize...\"\n",
    "        [{\"POS\": {\"IN\": [\"AUX\", \"VERB\"]}}, {\"LOWER\": \"will\"}]\n",
    "    ],\n",
    "    \"HIGH_CONF_ORG\": [\n",
    "        [{\"TEXT\": \"at\"}, {\"POS\": \"PROPN\", \"OP\": \"+\"}, {\"LOWER\": \"inc\"}] # \"at Acme Inc\"\n",
    "    ]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63c25932",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PII Entity Labels\n",
    "# Define PII categories that spaCy's NER typically detects and we want to anonymize.\n",
    "PII_ENTITY_LABELS = [\n",
    "    \"PERSON\",  # People, including fictional\n",
    "    \"NORP\",    # Nationalities or religious or political groups\n",
    "    \"FAC\",     # Buildings, airports, highways, bridges, etc.\n",
    "    \"ORG\",     # Companies, agencies, institutions, etc.\n",
    "    \"GPE\",     # Countries, cities, states\n",
    "    \"LOC\",     # Non-GPE locations, mountain ranges, bodies of water\n",
    "    \"PRODUCT\", # Objects, vehicles, foods, etc. (often proprietary names)\n",
    "    \"EVENT\",   # Named hurricanes, battles, wars, sports events, etc.\n",
    "    \"WORK_OF_ART\", # Titles of books, songs, etc.\n",
    "    \"LAW\",     # Named documents enacted into laws\n",
    "    \"LANGUAGE\",# Any named language\n",
    "    \"DATE\",    # Absolute or relative dates or periods\n",
    "    \"TIME\",    # Times smaller than a day\n",
    "    \"PERCENT\", # Percentage, including \"%\"\n",
    "    \"MONEY\",   # Monetary values, including unit\n",
    "    \"QUANTITY\",# Measurements, as of weight or distance\n",
    "    \"ORDINAL\", # \"first\", \"second\", etc.\n",
    "    \"CARDINAL\" # Numerals that do not fall under other types\n",
    "]\n",
    "\n",
    "# --- Regular Expressions for PII ---\n",
    "# These patterns catch common PII that may be missed by NER.\n",
    "# Define regex patterns for structured PII (email, phone, SSN, IP)\n",
    "PII_REGEX_PATTERNS = {\n",
    "    \"EMAIL\": r\"\\b[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\\.[A-Z|a-z]{2,}\\b\",\n",
    "    \"PHONE\": r\"(\\+\\d{1,2}\\s?)?\\(?\\d{3}\\)?[\\s.-]?\\d{3}[\\s.-]?\\d{4}\\b\",\n",
    "    \"SSN\": r\"\\b\\d{3}[-]?\\d{2}[-]?\\d{4}\\b\", # Simplified, US-specific SSN\n",
    "    \"IP_ADDRESS\": r\"\\b(?:[0-9]{1,3}\\.){3}[0-9]{1,3}\\b\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e62a28cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Custom/Override PII List (High Priority) ---\n",
    "# Add specific words/phrases that should ALWAYS be classified as a certain PII type.\n",
    "# This overrides spaCy's default behavior for these exact matches.\n",
    "CUSTOM_PII_OVERRIDES = [\n",
    "    {\"text\": \"Shashank\", \"type\": \"PERSON\"},\n",
    "    {\"text\": \"Google\", \"type\": \"ORG\"},\n",
    "    {\"text\": \"Apple\", \"type\": \"ORG\"},\n",
    "    {\"text\": \"Dr. Smith\", \"type\": \"PERSON\"},\n",
    "    # --- ADDED FOR INDIAN/ASIAN NAMES ---\n",
    "    {\"text\": \"Rajesh Sharma\", \"type\": \"PERSON\"},\n",
    "    {\"text\": \"Priyanka Singh\", \"type\": \"PERSON\"},\n",
    "    {\"text\": \"Ananya Das\", \"type\": \"PERSON\"},\n",
    "    {\"text\": \"Sameer Khan\", \"type\": \"PERSON\"},\n",
    "    {\"text\": \"Vikram Patel\", \"type\": \"PERSON\"},\n",
    "    {\"text\": \"Anjali Singh\", \"type\": \"PERSON\"},\n",
    "    {\"text\": \"Amit Kumar\", \"type\": \"PERSON\"},\n",
    "    {\"text\": \"Neha Sharma\", \"type\": \"PERSON\"},\n",
    "    {\"text\": \"Rohan Gupta\", \"type\": \"PERSON\"},\n",
    "    {\"text\": \"Sushma Reddy\", \"type\": \"PERSON\"},\n",
    "    {\"text\": \"Gaurav Singh\", \"type\": \"PERSON\"},\n",
    "    {\"text\": \"Divya Rao\", \"type\": \"PERSON\"},\n",
    "    {\"text\": \"Aisha Rahman\", \"type\": \"PERSON\"},\n",
    "    {\"text\": \"Kenji Tanaka\", \"type\": \"PERSON\"}, # Japanese name\n",
    "    {\"text\": \"Li Wei\", \"type\": \"PERSON\"},      # Chinese name\n",
    "    {\"text\": \"Maria Santos\", \"type\": \"PERSON\"}, # Filipino name, common in Asia\n",
    "    {\"text\": \"Kim Min-jun\", \"type\": \"PERSON\"}, # Korean name\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "924d8d82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Core Anonymization Logic (REDESIGNED with Context Awareness) ---\n",
    "def anonymize_text(text: str) -> (str, list):\n",
    "    \"\"\"\n",
    "    Detects PII with context-aware scoring, resolves overlaps,\n",
    "    and then anonymizes the text efficiently.\n",
    "    This version fixes the coordinate system bug that caused False Negatives.\n",
    "    \"\"\"\n",
    "    original_text_str = text\n",
    "    anonymized_text_chars = list(text)\n",
    "    \n",
    "    # 1. Collect All Raw Detections with a Confidence Score\n",
    "    doc = nlp(original_text_str)\n",
    "    raw_detections = []\n",
    "\n",
    "    # a. Custom Overrides (Highest Priority & Confidence)\n",
    "    for custom_pii_entry in CUSTOM_PII_OVERRIDES:\n",
    "        target_text = custom_pii_entry[\"text\"]\n",
    "        target_type = custom_pii_entry[\"type\"]\n",
    "        for match in re.finditer(re.escape(target_text), original_text_str):\n",
    "            raw_detections.append({\n",
    "                \"original_text_segment\": original_text_str[match.start():match.end()],\n",
    "                \"type\": target_type,\n",
    "                \"method\": \"Custom\",\n",
    "                \"start\": match.start(),\n",
    "                \"end\": match.end(),\n",
    "                \"confidence\": 1.0\n",
    "            })\n",
    "\n",
    "    # b. SpaCy NER Detections (Base Confidence)\n",
    "    for ent in doc.ents:\n",
    "        if ent.label_ in PII_ENTITY_LABELS:\n",
    "            confidence = 0.8\n",
    "            raw_detections.append({\n",
    "                \"original_text_segment\": original_text_str[ent.start_char:ent.end_char],\n",
    "                \"type\": ent.label_,\n",
    "                \"method\": \"NER\",\n",
    "                \"start\": ent.start_char,\n",
    "                \"end\": ent.end_char,\n",
    "                \"confidence\": confidence\n",
    "            })\n",
    "\n",
    "    # c. Apply Contextual Rules to adjust confidence of NER detections\n",
    "    matcher = Matcher(nlp.vocab)\n",
    "    for pii_type, patterns in CONTEXTUAL_RULES.items():\n",
    "        matcher.add(pii_type, patterns)\n",
    "    \n",
    "    matches = matcher(doc)\n",
    "    for match_id, start, end in matches:\n",
    "        span = doc[start:end]\n",
    "        match_type = nlp.vocab.strings[match_id]\n",
    "        \n",
    "        for det in raw_detections:\n",
    "            if span.start_char >= det['start'] and span.end_char <= det['end']:\n",
    "                if match_type.startswith(\"HIGH_CONF\"):\n",
    "                    det['confidence'] = 0.95\n",
    "                    det['method'] += \"_Context\"\n",
    "                elif match_type.startswith(\"LOW_CONF\"):\n",
    "                    det['confidence'] = 0.05\n",
    "                    det['method'] += \"_Context\"\n",
    "\n",
    "    # d. Regex Detections (Base Confidence)\n",
    "    for pii_type, pattern in PII_REGEX_PATTERNS.items():\n",
    "        for match in re.finditer(pattern, original_text_str):\n",
    "            confidence = 0.9\n",
    "            raw_detections.append({\n",
    "                \"original_text_segment\": original_text_str[match.start():match.end()],\n",
    "                \"type\": pii_type,\n",
    "                \"method\": \"Regex\",\n",
    "                \"start\": match.start(),\n",
    "                \"end\": match.end(),\n",
    "                \"confidence\": confidence\n",
    "            })\n",
    "\n",
    "    # e. Filter detections based on a confidence threshold\n",
    "    CONFIDENCE_THRESHOLD = 0.7\n",
    "    filtered_detections = [det for det in raw_detections if det['confidence'] >= CONFIDENCE_THRESHOLD]\n",
    "\n",
    "    # 2. Resolve Overlaps and Prioritize Final Detections\n",
    "    def sort_key_for_resolution(d):\n",
    "        return (-d['confidence'], d['start'], -(d['end'] - d['start']))\n",
    "\n",
    "    filtered_detections.sort(key=sort_key_for_resolution)\n",
    "    \n",
    "    anonymized_flags = [False] * len(original_text_str)\n",
    "    final_anonymization_plan = []\n",
    "\n",
    "    for det in filtered_detections:\n",
    "        is_already_covered = False\n",
    "        for i in range(det['start'], det['end']):\n",
    "            if i >= len(anonymized_flags) or anonymized_flags[i]:\n",
    "                is_already_covered = True\n",
    "                break\n",
    "        \n",
    "        if not is_already_covered:\n",
    "            final_anonymization_plan.append(det)\n",
    "            for i in range(det['start'], det['end']):\n",
    "                if i < len(anonymized_flags):\n",
    "                    anonymized_flags[i] = True\n",
    "    \n",
    "    # 3. Perform Anonymization on the Mutable Character List\n",
    "    final_anonymization_plan.sort(key=lambda x: x['start'], reverse=True)\n",
    "\n",
    "    pii_value_to_placeholder = {}\n",
    "    pii_type_counters = {label: 0 for label in PII_ENTITY_LABELS}\n",
    "    for regex_type in PII_REGEX_PATTERNS.keys():\n",
    "        if regex_type not in pii_type_counters:\n",
    "            pii_type_counters[regex_type] = 0\n",
    "\n",
    "    logged_detections = []\n",
    "    for det in final_anonymization_plan:\n",
    "        start_char, end_char = det['start'], det['end']\n",
    "        original_span_val = det['original_text_segment']\n",
    "        pii_type_val = det['type']\n",
    "        method_val = det['method']\n",
    "        \n",
    "        placeholder = \"\"\n",
    "        if method_val in [\"Custom\", \"NER\", \"NER_Context\"]:\n",
    "            pii_key = f\"{pii_type_val}_{original_span_val.strip()}\"\n",
    "            if pii_key not in pii_value_to_placeholder:\n",
    "                pii_type_counters[pii_type_val] += 1\n",
    "                placeholder = f\"{pii_type_val}_{pii_type_counters[pii_type_val]}\"\n",
    "                pii_value_to_placeholder[pii_key] = placeholder\n",
    "            else:\n",
    "                placeholder = pii_value_to_placeholder[pii_key]\n",
    "        else:\n",
    "            placeholder = f\"{pii_type_val}_REDACTED\"\n",
    "            \n",
    "        anonymized_text_chars[start_char:end_char] = list(placeholder)\n",
    "        logged_detections.append({\n",
    "            \"original_text\": original_span_val,\n",
    "            \"anonymized_type\": pii_type_val,\n",
    "            \"method\": method_val,\n",
    "            \"start_char\": start_char,\n",
    "            \"end_char\": end_char,\n",
    "            \"anonymized_placeholder\": placeholder,\n",
    "            \"confidence\": det.get(\"confidence\")\n",
    "        })\n",
    "        \n",
    "    return \"\".join(anonymized_text_chars), logged_detections\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "03def695",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- File Handling and Execution Logic for Notebook ---\n",
    "\n",
    "def run_anonymizer_notebook(input_filepath: str, output_filepath: str, log_filepath: str = None):\n",
    "    \"\"\"\n",
    "    Function to run the anonymization process within a Jupyter Notebook.\n",
    "\n",
    "    Args:\n",
    "        input_filepath (str): Path to the input text or CSV file.\n",
    "        output_filepath (str): Path for the anonymized output file.\n",
    "        log_filepath (str, optional): Path for the JSON log of detections.\n",
    "    \"\"\"\n",
    "    input_file = Path(input_filepath)\n",
    "    output_file = Path(output_filepath)\n",
    "    log_file = Path(log_filepath) if log_filepath else None\n",
    "\n",
    "    if not input_file.exists():\n",
    "        print(f\"Error: Input file '{input_file}' not found.\")\n",
    "        return\n",
    "\n",
    "    file_extension = input_file.suffix.lower()\n",
    "    content_to_anonymize = \"\"\n",
    "\n",
    "    print(f\"Processing '{input_file}'...\")\n",
    "\n",
    "    try:\n",
    "        if file_extension == \".txt\":\n",
    "            content_to_anonymize = input_file.read_text(encoding=\"utf-8\")\n",
    "        elif file_extension == \".csv\":\n",
    "            content_to_anonymize = input_file.read_text(encoding=\"utf-8\")\n",
    "        else:\n",
    "            print(f\"Error: Unsupported file type '{file_extension}'. Only .txt and .csv are supported in this version.\")\n",
    "            return\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading input file: {e}\")\n",
    "        return\n",
    "\n",
    "    # Perform anonymization\n",
    "    anonymized_content, detections = anonymize_text(content_to_anonymize)\n",
    "\n",
    "    # Write output\n",
    "    try:\n",
    "        output_file.write_text(anonymized_content, encoding=\"utf-8\")\n",
    "        print(f\"Anonymized content saved to '{output_file}'\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error writing output file: {e}\")\n",
    "        return\n",
    "\n",
    "    # Write log if requested\n",
    "    if log_file:\n",
    "        try:\n",
    "            with open(log_file, 'w', encoding=\"utf-8\") as f:\n",
    "                json.dump(detections, f, indent=4)\n",
    "            print(f\"Anonymization log saved to '{log_file}'\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error writing log file: {e}\")\n",
    "\n",
    "    print(f\"\\n--- Anonymization Summary ---\")\n",
    "    if detections:\n",
    "        print(f\"Total PII entities detected and anonymized: {len(detections)}\")\n",
    "        print(\"Detected entities (first 5 shown, see log for full list):\")\n",
    "        for i, det in enumerate(detections[:5]):\n",
    "            print(f\"  - Type: {det['anonymized_type']} (Method: {det['method']})\")\n",
    "            print(f\"    Original: '{det['original_text']}'\")\n",
    "            print(f\"    Replaced with: '{det['anonymized_placeholder']}'\")\n",
    "            if i < len(detections) - 1:\n",
    "                print(\"---\")\n",
    "    else:\n",
    "        print(\"No PII entities detected.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e74e112f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Running Anonymizer for CSV File ---\n",
      "Processing 'final_dataset.csv'...\n",
      "Anonymized content saved to 'anonymized_output.csv'\n",
      "Anonymization log saved to 'anonymization_log.json'\n",
      "\n",
      "--- Anonymization Summary ---\n",
      "Total PII entities detected and anonymized: 40489\n",
      "Detected entities (first 5 shown, see log for full list):\n",
      "  - Type: GPE (Method: NER)\n",
      "    Original: 'St, South'\n",
      "    Replaced with: 'GPE_1'\n",
      "---\n",
      "  - Type: EMAIL (Method: Regex)\n",
      "    Original: 'mohammed.al-hamdani@mail.net'\n",
      "    Replaced with: 'EMAIL_REDACTED'\n",
      "---\n",
      "  - Type: PERSON (Method: NER)\n",
      "    Original: 'Mohammed Al-Hamdani'\n",
      "    Replaced with: 'PERSON_1'\n",
      "---\n",
      "  - Type: EMAIL (Method: Regex)\n",
      "    Original: 'fatima.al-amri@sample.co'\n",
      "    Replaced with: 'EMAIL_REDACTED'\n",
      "---\n",
      "  - Type: PERSON (Method: NER)\n",
      "    Original: 'Fatima Al-Amri'\n",
      "    Replaced with: 'PERSON_2'\n",
      "---\n"
     ]
    }
   ],
   "source": [
    "# # --- Example 1: Anonymize a text file ---\n",
    "# input_text_file = \"sample_input.txt\"\n",
    "# output_text_file = \"anonymized_text_output.txt\"\n",
    "# log_text_file = \"anonymization_text_log.json\"\n",
    "\n",
    "# print(\"--- Running Anonymizer for Text File ---\")\n",
    "# run_anonymizer_notebook(input_text_file, output_text_file, log_text_file)\n",
    "\n",
    "# --- Anonymize a CSV file ---\n",
    "input_file = \"final_dataset.csv\"\n",
    "output_file = \"anonymized_output.csv\"\n",
    "log_file = \"anonymization_log.json\"\n",
    "\n",
    "print(\"\\n--- Running Anonymizer for CSV File ---\")\n",
    "run_anonymizer_notebook(input_file, output_file, log_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "163d5748",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Evaluation Metrics ---\n",
    "# Helper function to merge overlapping intervals (spans)\n",
    "def merge_intervals(intervals):\n",
    "    \"\"\"\n",
    "    Merges a list of [start, end] intervals (spans) into a minimal set of non-overlapping intervals.\n",
    "    Used to consolidate all PII spans detected by different methods into a single 'ground truth' reference.\n",
    "    \"\"\"\n",
    "    if not intervals:\n",
    "        return []\n",
    "    intervals.sort(key=lambda x: x[0])\n",
    "    merged = []\n",
    "    for interval in intervals:\n",
    "        if not merged or interval[0] > merged[-1][1]:\n",
    "            merged.append(list(interval))\n",
    "        else:\n",
    "            merged[-1][1] = max(merged[-1][1], interval[1])\n",
    "    return [tuple(m) for m in merged]\n",
    "\n",
    "def evaluate_anonymization_with_f1(original_text_path: str, anonymized_text_path: str, log_filepath: str):\n",
    "    \"\"\"\n",
    "    Evaluates the anonymization process by comparing the original text with the anonymized text\n",
    "    and analyzing the detection log, providing Precision, Recall, and F1-score.\n",
    "\n",
    "    Args:\n",
    "        original_text_path (str): Path to the original input text file.\n",
    "        anonymized_text_path (str): Path to the anonymized output file.\n",
    "        log_filepath (str): Path to the JSON log file of detections.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        original_text = Path(original_text_path).read_text(encoding=\"utf-8\")\n",
    "        anonymized_text = Path(anonymized_text_path).read_text(encoding=\"utf-8\")\n",
    "        with open(log_filepath, 'r', encoding=\"utf-8\") as f:\n",
    "            detections_log = json.load(f)\n",
    "    except FileNotFoundError as e:\n",
    "        print(f\"Error: Required file not found for evaluation: {e}\")\n",
    "        return\n",
    "    except json.JSONDecodeError as e:\n",
    "        print(f\"Error reading log file (JSON format issue): {e}\")\n",
    "        return\n",
    "    except Exception as e:\n",
    "        print(f\"An unexpected error occurred during file reading for evaluation: {e}\")\n",
    "        return\n",
    "\n",
    "    print(\"\\n--- Anonymization Evaluation (with P/R/F1) ---\")\n",
    "\n",
    "    # 1. Determine \"Ground Truth\" (based on our system's capabilities on original text)\n",
    "    # This serves as the reference for what our system *should* detect.\n",
    "    doc_original = nlp(original_text)\n",
    "    potential_pii_spans_raw = []\n",
    "\n",
    "    # Add NER entities from original text that match our PII_ENTITY_LABELS\n",
    "    for ent in doc_original.ents:\n",
    "        if ent.label_ in PII_ENTITY_LABELS:\n",
    "            potential_pii_spans_raw.append((ent.start_char, ent.end_char))\n",
    "\n",
    "    # Add Regex matches from original text\n",
    "    for pii_type, pattern in PII_REGEX_PATTERNS.items():\n",
    "        for match in re.finditer(pattern, original_text):\n",
    "            potential_pii_spans_raw.append((match.start(), match.end()))\n",
    "\n",
    "    # Merge overlapping spans to get a canonical set of PII regions\n",
    "    merged_potential_pii_spans = merge_intervals(potential_pii_spans_raw)\n",
    "    total_potential_pii_count = len(merged_potential_pii_spans)\n",
    "\n",
    "    # 2. Extract Detections Made by the Anonymizer from the Log\n",
    "    logged_detection_spans = [(d['start_char'], d['end_char']) for d in detections_log]\n",
    "    \n",
    "    # 3. Calculate True Positives (TP), False Positives (FP), False Negatives (FN)\n",
    "    #    Based on the \"Ground Truth\" as defined by `merged_potential_pii_spans`\n",
    "\n",
    "    # Initialize sets to track matched spans to avoid double counting\n",
    "    matched_potential_pii_spans = set() # Spans from merged_potential_pii_spans that were detected by a logged item\n",
    "    matched_logged_detection_spans = set() # Spans from logged_detection_spans that correctly overlapped a potential PII\n",
    "\n",
    "    # Determine overlaps between logged detections and potential PII\n",
    "    for i, (logged_s, logged_e) in enumerate(logged_detection_spans):\n",
    "        found_overlap_for_logged_detection = False \n",
    "        for j, (potential_s, potential_e) in enumerate(merged_potential_pii_spans):\n",
    "            # Check for any overlap. `max(start1, start2) < min(end1, end2)` indicates an overlap.\n",
    "            if max(logged_s, potential_s) < min(logged_e, potential_e):\n",
    "                matched_potential_pii_spans.add((potential_s, potential_e))\n",
    "                matched_logged_detection_spans.add((logged_s, logged_e))\n",
    "                found_overlap_for_logged_detection = True\n",
    "                break \n",
    "    \n",
    "    # TP (True Positives for Detection): Number of potential PII spans that were successfully detected and logged.\n",
    "    # This represents how many items from our system's \"ground truth\" were actually captured.\n",
    "    tp_detections = len(matched_potential_pii_spans)\n",
    "\n",
    "    # FP (False Positives for Detection): Number of logged detections that did NOT overlap with any potential PII span.\n",
    "    # This indicates cases where our anonymizer detected something that wasn't considered PII by our own rules.\n",
    "    fp_detections = len(logged_detection_spans) - len(matched_logged_detection_spans) \n",
    "\n",
    "    # FN (False Negatives for Detection): Number of potential PII spans that were NOT detected by any logged detection.\n",
    "    # This indicates PII that our rules *could* find, but our anonymizer missed.\n",
    "    fn_detections = total_potential_pii_count - tp_detections\n",
    "\n",
    "    print(f\"Total potential PII in original text (based on our rules): {total_potential_pii_count}\")\n",
    "    print(f\"Total PII entities logged by anonymizer: {len(logged_detection_spans)}\")\n",
    "    print(f\"TP (Correctly Detected PII): {tp_detections}\")\n",
    "    print(f\"FP (Incorrectly Detected as PII): {fp_detections}\")\n",
    "    print(f\"FN (Missed PII): {fn_detections}\")\n",
    "\n",
    "    # Calculate Precision, Recall, F1 Score for the DETECTION phase\n",
    "    precision = tp_detections / (tp_detections + fp_detections) if (tp_detections + fp_detections) > 0 else 0.0\n",
    "    recall = tp_detections / (tp_detections + fn_detections) if (tp_detections + fn_detections) > 0 else 0.0\n",
    "    f1_score = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0.0\n",
    "\n",
    "    print(f\"\\nPrecision (of Detection): {precision:.4f}\")\n",
    "    print(f\"Recall (of Detection):   {recall:.4f}\")\n",
    "    print(f\"F1-Score (of Detection): {f1_score:.4f}\")\n",
    "\n",
    "    # --- REVISED ANONYMIZATION EFFECTIVENESS RATE CALCULATION ---\n",
    "    # The previous check `original_span_in_log not in anonymized_text` was misleading\n",
    "    # because it checked the *entire document* for the original string,\n",
    "    # which might still be present if it appeared multiple times or in non-PII contexts.\n",
    "    #\n",
    "    # Given the design of `anonymize_text` (mutable list + reverse iteration),\n",
    "    # if an item is counted in `tp_detections` (i.e., it was a valid PII detection\n",
    "    # that our system logged), it implies the replacement *was executed* for that specific span.\n",
    "    #\n",
    "    # Thus, the 'success rate' of *replacing what was detected* should be high if not 100%.\n",
    "    # We will report on the proportion of logged detections that were True Positives.\n",
    "\n",
    "    successfully_removed_logged_items = tp_detections # Count of logged items that were valid PII (True Positives)\n",
    "\n",
    "    print(f\"\\nAnonymization Effectiveness (of logged detections):\")\n",
    "    print(f\"  {successfully_removed_logged_items} out of {len(logged_detection_spans)} detected items correspond to valid PII (True Positives).\")\n",
    "    \n",
    "    # This metric now tells us: Out of everything we *said* was PII and logged, how many were actually correct detections?\n",
    "    # Which is very close to your Precision of Detection, but reframed as 'effectiveness of handling logged items'.\n",
    "    anonymization_effectiveness_rate = successfully_removed_logged_items / len(logged_detection_spans) if len(logged_detection_spans) > 0 else 0.0\n",
    "    print(f\"  Effectiveness Rate (TPs among all Logged): {anonymization_effectiveness_rate:.4f}\")\n",
    "\n",
    "    # --- Manual Review Guidance ---\n",
    "    # The original \"To check for False Positives...\" guidance (commented out) can be re-added\n",
    "    # if desired, but for now we focus on the core metrics.\n",
    "    print(\"\\nTo check for False Negatives (actual PII missed by the anonymizer):\")\n",
    "    print(\"  - Compare the 'original_input.txt' (or .csv) with the 'anonymized_output.txt' (or .csv) line by line.\")\n",
    "    print(\"  - Look for any remaining PII in the anonymized file that should have been redacted/pseudonymized.\")\n",
    "    print(\"  - The calculated FN (Missed PII) above quantifies this based on what our rules *could* find.\")\n",
    "    \n",
    "    # Simple check for any remaining known PII patterns in the anonymized text (potential false negatives missed by replacement)\n",
    "    potential_false_negatives_regex_in_anonymized = []\n",
    "    for pii_type, pattern in PII_REGEX_PATTERNS.items():\n",
    "        for match in re.finditer(pattern, anonymized_text):\n",
    "            potential_false_negatives_regex_in_anonymized.append(f\"'{match.group(0)}' (Type: {pii_type})\")\n",
    "            \n",
    "    if potential_false_negatives_regex_in_anonymized:\n",
    "        print(f\"\\n  - Warning: Some original regex PII patterns found remaining in anonymized text:\")\n",
    "        for item in potential_false_negatives_regex_in_anonymized[:5]: # Show first 5\n",
    "            print(f\"    - {item}\")\n",
    "        if len(potential_false_negatives_regex_in_anonymized) > 5:\n",
    "            print(f\"    ...and {len(potential_false_negatives_regex_in_anonymized) - 5} more.\")\n",
    "    else:\n",
    "        print(\"  - No obvious remaining regex PII patterns found in anonymized text.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "Initiating Evaluation for CSV File Anonymization\n",
      "==================================================\n",
      "\n",
      "--- Anonymization Evaluation (with P/R/F1) ---\n",
      "Total potential PII in original text (based on our rules): 40317\n",
      "Total PII entities logged by anonymizer: 40420\n",
      "TP (Correctly Detected PII): 40317\n",
      "FP (Incorrectly Detected as PII): 1\n",
      "FN (Missed PII): 0\n",
      "\n",
      "Precision (of Detection): 1.0000\n",
      "Recall (of Detection):   1.0000\n",
      "F1-Score (of Detection): 1.0000\n",
      "\n",
      "Anonymization Effectiveness (of logged detections):\n",
      "  40317 out of 40420 detected items correspond to valid PII (True Positives).\n",
      "  Effectiveness Rate (TPs among all Logged): 0.9975\n",
      "\n",
      "To check for False Negatives (actual PII missed by the anonymizer):\n",
      "  - Compare the 'original_input.txt' (or .csv) with the 'anonymized_output.txt' (or .csv) line by line.\n",
      "  - Look for any remaining PII in the anonymized file that should have been redacted/pseudonymized.\n",
      "  - The calculated FN (Missed PII) above quantifies this based on what our rules *could* find.\n",
      "  - No obvious remaining regex PII patterns found in anonymized text.\n"
     ]
    }
   ],
   "source": [
    "# print(\"\\n\" + \"=\"*50)\n",
    "# print(\"Initiating Evaluation for Text File Anonymization\")\n",
    "# print(\"=\"*50)\n",
    "# evaluate_anonymization_with_f1(input_text_file, output_text_file, log_text_file)\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"Initiating Evaluation for CSV File Anonymization\")\n",
    "print(\"=\"*50)\n",
    "evaluate_anonymization_with_f1(input_file, output_file, log_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Function to Check for Undetected PII in Anonymized Output (False Negatives) ---\n",
    "\n",
    "def check_undetected_pii_in_output(original_filepath: str, anonymized_filepath: str, pii_regex_patterns: dict):\n",
    "    \"\"\"\n",
    "    Checks the anonymized output file for any remaining PII patterns defined by regex.\n",
    "    This helps identify False Negatives where PII was missed during anonymization.\n",
    "\n",
    "    Args:\n",
    "        original_filepath (str): Path to the original input text/CSV file.\n",
    "        anonymized_filepath (str): Path to the anonymized output text/CSV file.\n",
    "        pii_regex_patterns (dict): Dictionary of PII types and their regex patterns.\n",
    "    \"\"\"\n",
    "    print(f\"\\n--- Checking for Undetected PII (False Negatives) in '{Path(anonymized_filepath).name}' ---\")\n",
    "\n",
    "    try:\n",
    "        original_text = Path(original_filepath).read_text(encoding=\"utf-8\")\n",
    "        anonymized_text = Path(anonymized_filepath).read_text(encoding=\"utf-8\")\n",
    "    except FileNotFoundError as e:\n",
    "        print(f\"Error: File not found for checking undetected PII: {e}\")\n",
    "        return\n",
    "    except Exception as e:\n",
    "        print(f\"An unexpected error occurred while reading files: {e}\")\n",
    "        return\n",
    "\n",
    "    undetected_pii_found = False\n",
    "    all_undetected_details = []\n",
    "\n",
    "    # Check for remaining regex patterns in the anonymized text\n",
    "    for pii_type, pattern in pii_regex_patterns.items():\n",
    "        matches = list(re.finditer(pattern, anonymized_text))\n",
    "        if matches:\n",
    "            undetected_pii_found = True\n",
    "            print(f\"  - WARNING: '{pii_type}' patterns found remaining in anonymized text:\")\n",
    "            for match in matches:\n",
    "                span_start, span_end = match.span()\n",
    "                matched_text_in_anonymized = match.group(0)\n",
    "                \n",
    "                # --- IMPORTANT NOTE/CLARIFICATION FOR original_text_at_shifted_span ---\n",
    "                # The span_start and span_end are relative to `anonymized_text` because\n",
    "                # the regex search `re.finditer(pattern, anonymized_text)` runs on `anonymized_text`.\n",
    "                # If `anonymized_text` has undergone length changes (due to earlier anonymizations),\n",
    "                # then these spans will NOT correctly map back to the 'original_text' at the *same characters*.\n",
    "                # We're showing original_text[span_start:span_end] to give *some* context from original,\n",
    "                # but be aware its exact content might be misaligned if prior text was changed in length.\n",
    "                original_text_at_shifted_span = original_text[span_start:span_end] \n",
    "                # --- END NOTE ---\n",
    "\n",
    "                # Try to get surrounding context for better review\n",
    "                context_start = max(0, span_start - 20)\n",
    "                context_end = min(len(anonymized_text), span_end + 20)\n",
    "                anonymized_context_raw = anonymized_text[context_start:context_end]\n",
    "                \n",
    "                display_context = anonymized_context_raw.replace('\\n', ' ').strip()\n",
    "                highlighted_display_context = display_context.replace(matched_text_in_anonymized, f'>>>{matched_text_in_anonymized}<<<')\n",
    "\n",
    "                detail = {\n",
    "                    \"type\": pii_type,\n",
    "                    \"matched_text_in_anonymized\": matched_text_in_anonymized,\n",
    "                    \"original_text_at_shifted_span\": original_text_at_shifted_span, # Renamed for clarity\n",
    "                    \"start_char_in_anonymized\": span_start,\n",
    "                    \"end_char_in_anonymized\": span_end,\n",
    "                    \"anonymized_context\": display_context\n",
    "                }\n",
    "                all_undetected_details.append(detail)\n",
    "                \n",
    "                print(f\"    -> Type: {pii_type}, Text: '{matched_text_in_anonymized}' (from original at shifted span: '{original_text_at_shifted_span}')\")\n",
    "                print(f\"       Context (anonymized): '...{highlighted_display_context}...'\")\n",
    "                print(\"-\" * 50)\n",
    "\n",
    "    if not undetected_pii_found:\n",
    "        print(\"  No obvious remaining regex PII patterns found. (Good!)\")\n",
    "    else:\n",
    "        print(f\"\\nSummary: {len(all_undetected_details)} instances of regex-definable PII were found in the anonymized output.\")\n",
    "        print(\"Please review these carefully, as they indicate False Negatives.\")\n",
    "        # Optionally save to a file for detailed review\n",
    "        # with open(f\"{Path(anonymized_filepath).stem}_undetected_pii.json\", 'w', encoding='utf-8') as f:\n",
    "        #     json.dump(all_undetected_details, f, indent=4)\n",
    "        # print(f\"Detailed undetected PII log saved to {Path(anonymized_filepath).stem}_undetected_pii.json\")\n",
    "\n",
    "    print(f\"--- Finished checking '{Path(anonymized_filepath).name}' ---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Checking for Undetected PII (False Negatives) in 'anonymized_output1.csv' ---\n",
      "  No obvious remaining regex PII patterns found. (Good!)\n",
      "--- Finished checking 'anonymized_output1.csv' ---\n"
     ]
    }
   ],
   "source": [
    "# Call for Text File\n",
    "#check_undetected_pii_in_output(input_text_file, output_text_file, PII_REGEX_PATTERNS)\n",
    "\n",
    "# Call for CSV File\n",
    "check_undetected_pii_in_output(input_file, output_file, PII_REGEX_PATTERNS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Function for Re-Anonymization of Missed PII (Second Pass for FNs) ---\n",
    "\n",
    "def re_anonymize_missed_pii(\n",
    "    input_anonymized_filepath: str,\n",
    "    output_re_anonymized_filepath: str,\n",
    "    pii_regex_patterns: dict,\n",
    "):\n",
    "    \"\"\"\n",
    "    Performs a second anonymization pass specifically to mask PII that was\n",
    "    missed in the first pass, focusing on regex-definable patterns.\n",
    "\n",
    "    Args:\n",
    "        input_anonymized_filepath (str): Path to the output file from the first anonymization pass.\n",
    "        output_re_anonymized_filepath (str): Path where the re-anonymized output will be saved.\n",
    "        pii_regex_patterns (dict): Dictionary of PII types and their regex patterns to re-check.\n",
    "    \n",
    "    Returns:\n",
    "        tuple: A tuple containing:\n",
    "            - str: The re-anonymized text.\n",
    "            - list: A list of dictionaries describing the newly detected and re-anonymized PII.\n",
    "    \"\"\"\n",
    "    print(f\"\\n--- Initiating Re-Anonymization Pass for '{Path(input_anonymized_filepath).name}' ---\")\n",
    "    print(f\"  Input file for re-masking: '{input_anonymized_filepath}'\")\n",
    "    print(f\"  Output file for re-masked content: '{output_re_anonymized_filepath}'\")\n",
    "\n",
    "    try:\n",
    "        current_anonymized_text = Path(input_anonymized_filepath).read_text(encoding=\"utf-8\")\n",
    "        print(f\"  Successfully read {len(current_anonymized_text)} characters from input for re-masking.\")\n",
    "    except FileNotFoundError as e:\n",
    "        print(f\"ERROR: Input anonymized file not found for re-masking: {e}\")\n",
    "        return \"\", []\n",
    "    except Exception as e:\n",
    "        print(f\"ERROR: An unexpected error occurred while reading the anonymized file for re-masking: {e}\")\n",
    "        return \"\", []\n",
    "\n",
    "    re_anonymized_text_chars = list(current_anonymized_text) # Mutable list for re-masking\n",
    "    newly_masked_detections = [] # Log for this second pass\n",
    "\n",
    "    # Collect new detections and prepare for re-anonymization\n",
    "    potential_new_masks = []\n",
    "    print(\"  Searching for missed regex PII in the current text for re-masking...\")\n",
    "    for pii_type, pattern in pii_regex_patterns.items():\n",
    "        for match in re.finditer(pattern, current_anonymized_text):\n",
    "            # These are the PII that were missed by the first pass's overlap logic\n",
    "            # and are still present in the text.\n",
    "            potential_new_masks.append({\n",
    "                \"original_text_segment\": match.group(0), # What was actually found in the current (anonymized) text\n",
    "                \"type\": pii_type,\n",
    "                \"method\": \"Regex_Remask\", # Indicate it's from the second pass\n",
    "                \"start\": match.start(),\n",
    "                \"end\": match.end()\n",
    "            })\n",
    "    \n",
    "    # Sort these new detections in reverse order of their start positions\n",
    "    # to perform in-place modification correctly.\n",
    "    potential_new_masks.sort(key=lambda x: x['start'], reverse=True)\n",
    "\n",
    "    print(f\"  Found {len(potential_new_masks)} new PII instances to re-mask in this pass.\")\n",
    "\n",
    "    if not potential_new_masks:\n",
    "        print(\"  No further regex-definable PII found to re-mask. (Pass not needed)\")\n",
    "        # If no changes needed, just save the content to the new output path\n",
    "        Path(output_re_anonymized_filepath).write_text(current_anonymized_text, encoding=\"utf-8\")\n",
    "        print(f\"  Original anonymized content saved to '{output_re_anonymized_filepath}' (no new masks applied).\")\n",
    "        return current_anonymized_text, newly_masked_detections\n",
    "\n",
    "    for det in potential_new_masks:\n",
    "        start_char, end_char = det['start'], det['end']\n",
    "        pii_type_val = det['type']\n",
    "        \n",
    "        # For re-masking, we'll always use redaction.\n",
    "        placeholder = f\"{pii_type_val}_REDACTED_REMASKED\" # Clear indicator it was a second pass mask\n",
    "            \n",
    "        # Perform the in-place replacement\n",
    "        re_anonymized_text_chars[start_char:end_char] = list(placeholder)\n",
    "\n",
    "        # Log the details of this re-masking\n",
    "        newly_masked_detections.append({\n",
    "            \"original_text\": det['original_text_segment'],\n",
    "            \"anonymized_type\": pii_type_val,\n",
    "            \"method\": \"Regex_Remask\",\n",
    "            \"start_char\": start_char,\n",
    "            \"end_char\": end_char,\n",
    "            \"anonymized_placeholder\": placeholder\n",
    "        })\n",
    "    \n",
    "    re_anonymized_content = \"\".join(re_anonymized_text_chars)\n",
    "\n",
    "    try:\n",
    "        Path(output_re_anonymized_filepath).write_text(re_anonymized_content, encoding=\"utf-8\")\n",
    "        print(f\"  Successfully wrote {len(re_anonymized_content)} characters to '{output_re_anonymized_filepath}'\")\n",
    "    except Exception as e:\n",
    "        print(f\"ERROR: Failed to write re-anonymized output file: {e}\")\n",
    "\n",
    "    print(f\"--- Re-masking pass complete. {len(newly_masked_detections)} items re-masked. ---\")\n",
    "    return re_anonymized_content, newly_masked_detections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Initiating Re-Anonymization Pass for 'anonymized_output1.csv' ---\n",
      "  Input file for re-masking: 'anonymized_output1.csv'\n",
      "  Output file for re-masked content: 're_anonymized_csv_output.csv'\n",
      "  Successfully read 19342 characters from input for re-masking.\n",
      "  Searching for missed regex PII in the current text for re-masking...\n",
      "  Found 0 new PII instances to re-mask in this pass.\n",
      "  No further regex-definable PII found to re-mask. (Pass not needed)\n",
      "  Original anonymized content saved to 're_anonymized_csv_output.csv' (no new masks applied).\n",
      "\n",
      "--- Verifying Re-Anonymized CSV File for Residual PII ---\n",
      "\n",
      "--- Checking for Undetected PII (False Negatives) in 're_anonymized_csv_output.csv' ---\n",
      "  No obvious remaining regex PII patterns found. (Good!)\n",
      "--- Finished checking 're_anonymized_csv_output.csv' ---\n"
     ]
    }
   ],
   "source": [
    "# --- Execute Re-Anonymization of Missed PII ---\n",
    "\n",
    "# Define new output paths for the re-anonymized files\n",
    "re_anonymized_text_file = \"re_anonymized_text_output.txt\"\n",
    "re_anonymization_text_log_file = \"re_anonymization_text_log.json\"\n",
    "\n",
    "re_anonymized_csv_file = \"re_anonymized_csv_output.csv\"\n",
    "re_anonymization_csv_log_file = \"re_anonymization_csv_log.json\"\n",
    "\n",
    "# --- Re-anonymize Text File ---\n",
    "# re_masked_text_content, re_masked_text_detections = re_anonymize_missed_pii(\n",
    "#     input_anonymized_filepath=output_text_file, # Output from first pass\n",
    "#     output_re_anonymized_filepath=re_anonymized_text_file,\n",
    "#     pii_regex_patterns=PII_REGEX_PATTERNS\n",
    "# )\n",
    "# Save the log for the re-masked items\n",
    "# if re_masked_text_detections:\n",
    "#     with open(re_anonymization_text_log_file, 'w', encoding=\"utf-8\") as f:\n",
    "#         json.dump(re_masked_text_detections, f, indent=4)\n",
    "#     print(f\"Re-anonymization log for text saved to '{re_anonymization_text_log_file}'\")\n",
    "\n",
    "# --- Re-anonymize CSV File ---\n",
    "re_masked_csv_content, re_masked_csv_detections = re_anonymize_missed_pii(\n",
    "    input_anonymized_filepath=output_file, # Output from first pass\n",
    "    output_re_anonymized_filepath=re_anonymized_csv_file,\n",
    "    pii_regex_patterns=PII_REGEX_PATTERNS\n",
    ")\n",
    "# Save the log for the re-masked items\n",
    "if re_masked_csv_detections:\n",
    "    with open(re_anonymization_csv_log_file, 'w', encoding=\"utf-8\") as f:\n",
    "        json.dump(re_masked_csv_detections, f, indent=4)\n",
    "    print(f\"Re-anonymization log for CSV saved to '{re_anonymization_csv_log_file}'\")\n",
    "\n",
    "# --- OPTIONAL: Re-run the Undetected PII Check (from the original script)\n",
    "#    on the *newly re-anonymized* files to confirm the fix.\n",
    "#    You would need the check_undetected_pii_in_output function defined earlier.\n",
    "#\n",
    "# print(\"\\n--- Verifying Re-Anonymized Text File for Residual PII ---\")\n",
    "# check_undetected_pii_in_output(input_text_file, re_anonymized_text_file, PII_REGEX_PATTERNS)\n",
    "#\n",
    "print(\"\\n--- Verifying Re-Anonymized CSV File for Residual PII ---\")\n",
    "check_undetected_pii_in_output(output_file, re_anonymized_csv_file, PII_REGEX_PATTERNS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6c7e44b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "STAGE 1: Executing Secondary Re-Anonymization Pass\n",
      "==================================================\n",
      "\n",
      "--- Initiating Re-Anonymization Pass for 'anonymized_output1.csv' ---\n",
      "  Input file for re-masking: 'anonymized_output1.csv'\n",
      "  Output file for re-masked content: 're_anonymized_csv_output.csv'\n",
      "  Successfully read 19342 characters from input for re-masking.\n",
      "  Searching for missed regex PII in the current text for re-masking...\n",
      "  Found 0 new PII instances to re-mask in this pass.\n",
      "  No further regex-definable PII found to re-mask. (Pass not needed)\n",
      "  Original anonymized content saved to 're_anonymized_csv_output.csv' (no new masks applied).\n",
      "\n",
      "==================================================\n",
      "STAGE 2: Verifying Re-Anonymized Files for Residual PII (False Negatives)\n",
      "==================================================\n",
      "\n",
      "--- Checking Re-Anonymized CSV File ---\n",
      "\n",
      "--- Checking for Undetected PII (False Negatives) in 're_anonymized_csv_output.csv' ---\n",
      "  No obvious remaining regex PII patterns found. (Good!)\n",
      "--- Finished checking 're_anonymized_csv_output.csv' ---\n"
     ]
    }
   ],
   "source": [
    "# --- Execute Secondary Re-Anonymization Pass and Verification ---\n",
    "re_anonymized_csv_file = \"re_anonymized_csv_output.csv\"\n",
    "re_anonymization_csv_log_file = \"re_anonymization_csv_log.json\" # Log for items masked in second pass\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"STAGE 1: Executing Secondary Re-Anonymization Pass\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# --- Re-anonymize Text File ---\n",
    "# re_masked_text_content, re_masked_text_detections = re_anonymize_missed_pii(\n",
    "#     input_anonymized_filepath=output_text_file, # Input is the output from the first pass\n",
    "#     output_re_anonymized_filepath=re_anonymized_text_file,\n",
    "#     pii_regex_patterns=PII_REGEX_PATTERNS\n",
    "# )\n",
    "# if re_masked_text_detections:\n",
    "#     with open(re_anonymization_text_log_file, 'w', encoding=\"utf-8\") as f:\n",
    "#         json.dump(re_masked_text_detections, f, indent=4)\n",
    "#     print(f\"  Re-anonymization log for text saved to '{re_anonymization_text_log_file}'\")\n",
    "\n",
    "# --- Re-anonymize CSV File ---\n",
    "re_masked_csv_content, re_masked_csv_detections = re_anonymize_missed_pii(\n",
    "    input_anonymized_filepath=output_file, # Input is the output from the first pass\n",
    "    output_re_anonymized_filepath=re_anonymized_csv_file,\n",
    "    pii_regex_patterns=PII_REGEX_PATTERNS\n",
    ")\n",
    "if re_masked_csv_detections:\n",
    "    with open(re_anonymization_csv_log_file, 'w', encoding=\"utf-8\") as f:\n",
    "        json.dump(re_masked_csv_detections, f, indent=4)\n",
    "    print(f\"  Re-anonymization log for CSV saved to '{re_anonymization_csv_log_file}'\")\n",
    "\n",
    "\n",
    "# --- Perform Checks for Undetected PII on the NEWLY RE-ANONYMIZED FILES ---\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"STAGE 2: Verifying Re-Anonymized Files for Residual PII (False Negatives)\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# --- Verifying Re-Anonymized Text File ---\n",
    "# Pass the *output of the re-masking pass* to the check function\n",
    "# (This assumes check_undetected_pii_in_output is defined in a prior cell)\n",
    "# print(\"\\n--- Checking Re-Anonymized Text File ---\")\n",
    "# check_undetected_pii_in_output(input_text_file, re_anonymized_text_file, PII_REGEX_PATTERNS)\n",
    "\n",
    "# --- Verifying Re-Anonymized CSV File ---\n",
    "# Pass the *output of the re-masking pass* to the check function\n",
    "print(\"\\n--- Checking Re-Anonymized CSV File ---\")\n",
    "check_undetected_pii_in_output(input_file, re_anonymized_csv_file, PII_REGEX_PATTERNS)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41135cb8",
   "metadata": {},
   "source": [
    "Final Code ends here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "013a1d4f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80423065",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fff4d07-c3a7-4228-8617-3430ddc431dc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
